{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09934069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Chargement des mod√®les...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/processed/tfidf_vectorizer.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müì¶ Chargement des mod√®les...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# üü¢ Chemin correct pour ton vectorizer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m vectorizer = \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/processed/tfidf_vectorizer.joblib\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m encoder    = joblib.load(\u001b[33m\"\u001b[39m\u001b[33mdata/models/label_encoder.joblib\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m bst        = xgb.Booster()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/joblib/numpy_pickle.py:735\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    733\u001b[39m         obj = _unpickle(fobj, ensure_native_byte_order=ensure_native_byte_order)\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[32m    737\u001b[39m             fobj,\n\u001b[32m    738\u001b[39m             validated_mmap_mode,\n\u001b[32m    739\u001b[39m         ):\n\u001b[32m    740\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    741\u001b[39m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[32m    742\u001b[39m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[32m    743\u001b[39m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/processed/tfidf_vectorizer.joblib'"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üîÆ INF√âRENCE ‚Äì TF-IDF + ResNet50 + XGBoost (version corrig√©e)\n",
    "# ============================================================\n",
    "\n",
    "import os, re, html, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import xgboost as xgb\n",
    "from bs4 import BeautifulSoup\n",
    "from scipy import sparse\n",
    "\n",
    "# ============================================================\n",
    "# 1Ô∏è‚É£ Chargement des artefacts\n",
    "# ============================================================\n",
    "print(\"üì¶ Chargement des mod√®les...\")\n",
    "\n",
    "# üü¢ Chemin correct pour ton vectorizer\n",
    "vectorizer = joblib.load(\"data/processed/tfidf_vectorizer.joblib\")\n",
    "encoder    = joblib.load(\"data/models/label_encoder.joblib\")\n",
    "bst        = xgb.Booster()\n",
    "bst.load_model(\"data/models/xgb_fusion.json\")\n",
    "\n",
    "print(\"‚úÖ Artefacts charg√©s avec succ√®s.\")\n",
    "\n",
    "# ============================================================\n",
    "# 2Ô∏è‚É£ Fonction de nettoyage texte\n",
    "# ============================================================\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text(\" \")\n",
    "    text = html.unescape(text)\n",
    "    text = re.sub(r\"[^A-Za-z√Ä-√ñ√ò-√∂√∏-√ø0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip().lower()\n",
    "    return text\n",
    "\n",
    "# ============================================================\n",
    "# 3Ô∏è‚É£ Charger une ligne du CSV\n",
    "# ============================================================\n",
    "df = pd.read_csv(\"data/X_train_update.csv\")\n",
    "sample = df.sample(1, random_state=42).iloc[0]\n",
    "\n",
    "designation = str(sample[\"designation\"])\n",
    "description = str(sample[\"description\"])\n",
    "imageid     = str(sample[\"imageid\"])\n",
    "\n",
    "print(f\"\\nüßæ Produit test√© : {designation[:80]}...\")\n",
    "\n",
    "# ============================================================\n",
    "# 4Ô∏è‚É£ TF-IDF texte\n",
    "# ============================================================\n",
    "text_clean = clean_text(designation + \" \" + description)\n",
    "X_text = vectorizer.transform([text_clean])\n",
    "\n",
    "# ============================================================\n",
    "# 5Ô∏è‚É£ Embeddings image (ResNet50 PyTorch)\n",
    "# ============================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "resnet.fc = torch.nn.Identity()\n",
    "resnet.eval().to(device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "img_path = f\"data/images/images/image_train/{imageid}.jpg\"\n",
    "try:\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        X_img = resnet(x).cpu().numpy()\n",
    "except Exception:\n",
    "    print(\"‚ö†Ô∏è Image introuvable ‚Üí vecteur nul utilis√©.\")\n",
    "    X_img = np.zeros((1, 2048), dtype=np.float32)\n",
    "\n",
    "# ============================================================\n",
    "# 6Ô∏è‚É£ Fusion texte + image\n",
    "# ============================================================\n",
    "X_all = sparse.hstack([X_text, sparse.csr_matrix(X_img)]).tocsr()\n",
    "\n",
    "# ============================================================\n",
    "# 7Ô∏è‚É£ Pr√©diction XGBoost\n",
    "# ============================================================\n",
    "dtest = xgb.DMatrix(X_all)\n",
    "proba = bst.predict(dtest)[0]\n",
    "pred_id = np.argmax(proba)\n",
    "prdtypecode = encoder.inverse_transform([pred_id])[0]\n",
    "\n",
    "print(f\"\\nüéØ Code produit pr√©dit : {prdtypecode}\")\n",
    "\n",
    "# ============================================================\n",
    "# 8Ô∏è‚É£ Top-5 pr√©dictions + cat√©gories\n",
    "# ============================================================\n",
    "top5_idx = np.argsort(proba)[::-1][:5]\n",
    "top5_codes = encoder.inverse_transform(top5_idx)\n",
    "top5_scores = proba[top5_idx]\n",
    "\n",
    "cat_map = {\n",
    "    10:  \"Livres et ouvrages culturels\",\n",
    "    40:  \"Jeux vid√©o et accessoires\",\n",
    "    50:  \"Accessoires gaming\",\n",
    "    60:  \"Consoles r√©tro\",\n",
    "    1140:\"Figurines Pop & licences geek\",\n",
    "    1160:\"Cartes √† collectionner\",\n",
    "    1180:\"Jeux de figurines & wargames\",\n",
    "    1280:\"Jouets enfants & b√©b√©s\",\n",
    "    1281:\"Jeux et loisirs enfants\",\n",
    "    1300:\"Drones et mod√®les r√©duits\",\n",
    "    1301:\"Chaussettes & accessoires enfants\",\n",
    "    1302:\"Jouets divers & loisirs cr√©atifs\",\n",
    "    1320:\"Pu√©riculture & √©quipement b√©b√©\",\n",
    "    1560:\"Mobilier & articles de maison\",\n",
    "    1920:\"Linge de maison & d√©coration textile\",\n",
    "    1940:\"Alimentation & boissons\",\n",
    "    2060:\"D√©coration & accessoires saisonniers\",\n",
    "    2220:\"Accessoires pour animaux\",\n",
    "    2280:\"Magazines & journaux anciens\",\n",
    "    2403:\"Livres, mangas & partitions\",\n",
    "    2462:\"Lots jeux vid√©o et consoles\",\n",
    "    2522:\"Fournitures de papeterie\",\n",
    "    2582:\"Mobilier et accessoires de jardin\",\n",
    "    2583:\"Accessoires pour piscines et spas\",\n",
    "    2585:\"Outils et √©quipements de jardinage\",\n",
    "    2705:\"Essais & livres d‚Äôhistoire\",\n",
    "    2905:\"Jeux PC √† t√©l√©charger & √©ditions sp√©ciales\",\n",
    "}\n",
    "\n",
    "print(\"\\nüèÜ Top-5 pr√©dictions :\")\n",
    "for c, s in zip(top5_codes, top5_scores):\n",
    "    name = cat_map.get(int(c), \"Non d√©fini\")\n",
    "    print(f\"  {c:<6} | {s:.3f} | {name}\")\n",
    "\n",
    "if int(prdtypecode) in cat_map:\n",
    "    print(f\"\\nü™Ñ Cat√©gorie pr√©dite : {cat_map[int(prdtypecode)]}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Cat√©gorie non r√©f√©renc√©e dans le mapping local.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
