"""
=====================================================================
üèãÔ∏è‚Äç‚ôÇÔ∏è  Script : train.py ‚Äî Entra√Ænement du mod√®le Rakuten XGBoost fusion
=====================================================================

üéØ Objectif :
-------------
Ce script entra√Æne un mod√®le de classification multimodale (texte + image)
pour pr√©dire le code produit Rakuten (`prdtypecode`) √† partir de donn√©es
pr√©-fusionn√©es (features texte TF-IDF + features image ResNet).

Il assure :
  - le chargement des jeux de donn√©es d√©j√† pr√©-trait√©s (.npz, .npy),
  - l‚Äôencodage des labels,
  - l‚Äôentra√Ænement du mod√®le XGBoost avec suivi des m√©triques via MLflow,
  - la sauvegarde des artefacts (mod√®le, encodeur, m√©triques).

üìÅ Donn√©es attendues :
----------------------
Les fichiers doivent √™tre pr√©sents dans :  data/processed/
  - X_train.npz   : features d‚Äôentra√Ænement (texte + image)
  - X_val.npz     : features de validation
  - y_train.npy   : labels d‚Äôentra√Ænement
  - y_val.npy     : labels de validation

üß† Sorties g√©n√©r√©es :
---------------------
Les artefacts du mod√®le sont sauvegard√©s dans :  data/models/
  - xgb_fusion.json          ‚Üí mod√®le XGBoost entra√Æn√©
  - label_encoder.joblib     ‚Üí encodeur des labels scikit-learn
  - metrics_fusion.json      ‚Üí m√©triques (accuracy, F1)

üìä Suivi des exp√©riences :
--------------------------
Les logs d‚Äôexp√©riences sont enregistr√©s dans :  mlruns/
  - tracking local MLflow (backend = file:./mlruns)
  - enregistre les param√®tres, m√©triques et artefacts

üîÅ Fonction principale :
------------------------
train() :
    ‚Ä¢ charge les donn√©es
    ‚Ä¢ entra√Æne le mod√®le
    ‚Ä¢ log les m√©triques et artefacts MLflow
    ‚Ä¢ retourne un dictionnaire Python :
        {"status": "done", "accuracy": float, "f1": float}

üì¶ Utilisation :
----------------
‚ñ∂Ô∏è En ligne de commande :
    python src/train/train.py

‚ñ∂Ô∏è En module (API, orchestrateur, etc.) :
    from train.train import train
    result = train()

‚öôÔ∏è Int√©gration Docker :
-----------------------
Le Dockerfile associ√© ex√©cute ce script via :
    CMD ["python", "-m", "train.train"]
avec volumes mont√©s pour `data/` et `mlruns/`.

=====================================================================
"""

# --- train.py : Entra√Ænement XGBoost fusion texte+image avec MLflow ---
import json
import os
from datetime import datetime

import joblib
import mlflow
import mlflow.xgboost
import numpy as np
import xgboost as xgb
from scipy import sparse
from sklearn.metrics import accuracy_score, classification_report, f1_score
from sklearn.preprocessing import LabelEncoder
from tqdm.auto import tqdm

from src.data.clean_data import calcul_lignes_a_lire, clean_data
from src.data.preprocess_data import preprocess_data


# === 0Ô∏è‚É£ Gestion des chemins ===
# R√©cup√®re la racine du projet, peu importe d'o√π on ex√©cute le script
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "../.."))
RAW_DIR = os.path.join(BASE_DIR, "data", "raw")
IMG_DIR = os.path.join(RAW_DIR, "images", "images")
DATA_DIR = os.path.join(BASE_DIR, "data", "processed")
MODEL_DIR = os.path.join(BASE_DIR, "models")
MLRUNS_DIR = os.path.join(BASE_DIR, "mlruns")

os.makedirs(MODEL_DIR, exist_ok=True)
os.makedirs(MLRUNS_DIR, exist_ok=True)

print("üìÇ BASE_DIR :", BASE_DIR)
print("üìÇ RAW_DIR :", RAW_DIR)
print("üìÇ IMG_DIR :", IMG_DIR)
print("üìÇ DATA_DIR :", DATA_DIR)
print("üìÇ MODEL_DIR :", MODEL_DIR)
print("üìÇ MLRUNS_DIR :", MLRUNS_DIR)

# üîπ MLflow local : stocke les runs dans le dossier mlruns √† la racine
mlflow.set_tracking_uri(f"file:{MLRUNS_DIR}")
mlflow.set_experiment("rakuten_xgb_fusion")


def train():
    print("üßπ Starting data cleaning process...")
    nb_lignes = calcul_lignes_a_lire(datetime.now().strftime("%Y-%m-%d"))
    clean_data(input_dir=RAW_DIR, images_dir=IMG_DIR, nbre_lignes=nb_lignes)

    print("‚öôÔ∏è Starting data preprocessing...")
    preprocess_data(
        output_dir=DATA_DIR, input_model=os.path.join(MODEL_DIR, "resnet50-weights.pth")
    )

    print("üöÄ Starting training process...")

    # === 1Ô∏è‚É£ Chargement des donn√©es pr√©-fusionn√©es ===
    X_train = sparse.load_npz(os.path.join(DATA_DIR, "X_train.npz"))
    X_val = sparse.load_npz(os.path.join(DATA_DIR, "X_val.npz"))
    y_train = np.load(os.path.join(DATA_DIR, "y_train.npy"))
    y_val = np.load(os.path.join(DATA_DIR, "y_val.npy"))

    print(f"üì¶ X_train: {X_train.shape}, X_val: {X_val.shape}")
    print(f"üìä y_train: {y_train.shape}, y_val: {y_val.shape}")

    # === 2Ô∏è‚É£ Encodage des labels ===
    encoder = LabelEncoder()
    y_train_enc = encoder.fit_transform(y_train)
    y_val_enc = encoder.transform(y_val)

    dtrain = xgb.DMatrix(X_train, label=y_train_enc)
    dval = xgb.DMatrix(X_val, label=y_val_enc)

    # === 3Ô∏è‚É£ Param√®tres du mod√®le ===
    device = "cuda" if gpu_available() else "cpu"
    params = {
        "objective": "multi:softprob",
        "num_class": len(np.unique(y_train_enc)),
        "eval_metric": ["mlogloss", "merror"],
        "eta": 0.1,
        "max_depth": 8,
        "subsample": 0.8,
        "colsample_bytree": 0.8,
        "tree_method": "hist",
        "device": device,
    }

    num_round = 50
    evals_result = {}

    # === 4Ô∏è‚É£ Callback de progression ===
    class TQDMProgress(xgb.callback.TrainingCallback):
        def __init__(self, total):
            self.pbar = tqdm(total=total, desc="üß† Training")

        def after_iteration(self, model, epoch, evals_log):
            self.pbar.update(1)
            tr = evals_log["train"]["mlogloss"][-1]
            va = evals_log["val"]["mlogloss"][-1]
            self.pbar.set_postfix({"train": f"{tr:.4f}", "val": f"{va:.4f}"})
            return False

        def after_training(self, model):
            self.pbar.close()
            return model

    # === 5Ô∏è‚É£ Entra√Ænement + suivi MLflow ===
    with mlflow.start_run(run_name="train_xgb_fusion"):
        mlflow.log_params(params)

        bst = xgb.train(
            params=params,
            dtrain=dtrain,
            num_boost_round=num_round,
            evals=[(dtrain, "train"), (dval, "val")],
            evals_result=evals_result,
            verbose_eval=False,
            callbacks=[TQDMProgress(num_round)],
        )

        # === 6Ô∏è‚É£ √âvaluation sur validation ===
        y_pred = np.argmax(bst.predict(dval), axis=1)
        acc = accuracy_score(y_val_enc, y_pred)
        f1 = f1_score(y_val_enc, y_pred, average="weighted")

        print(f"‚úÖ Accuracy: {acc:.4f} | F1: {f1:.4f}")
        print("=== Rapport (r√©sum√©) ===")
        print(classification_report(y_val_enc, y_pred, digits=3)[:800])

        mlflow.log_metrics({"accuracy": float(acc), "f1": float(f1)})

        # === 7Ô∏è‚É£ Sauvegardes locales ===
        model_path = os.path.join(MODEL_DIR, "xgb_fusion.json")
        encoder_path = os.path.join(MODEL_DIR, "label_encoder.joblib")
        metrics_path = os.path.join(MODEL_DIR, "metrics_fusion.json")

        bst.save_model(model_path)
        joblib.dump(encoder, encoder_path)
        json.dump({"accuracy": float(acc), "f1": float(f1)}, open(metrics_path, "w"))

        # === 8Ô∏è‚É£ Logging MLflow des artefacts ===
        mlflow.xgboost.log_model(bst, artifact_path="xgb_model")
        mlflow.log_artifact(encoder_path, artifact_path="preprocessing")
        mlflow.log_artifact(metrics_path, artifact_path="metrics")

    print("üíæ Model saved:", model_path)
    print("‚úÖ Training done successfully.")
    return {"status": "done", "accuracy": acc, "f1": f1}


def gpu_available():
    """
    Teste si un GPU compatible CUDA est disponible pour XGBoost.

    Essaie d'entra√Æner un mod√®le minimal avec les param√®tres GPU.
    Si l'entra√Ænement r√©ussit, retourne True (GPU disponible),
    sinon retourne False (pas de GPU ou erreur de configuration).

    Utile pour adapter dynamiquement le param√®tre 'device' lors de l'entra√Ænement
    afin d'utiliser le GPU si possible, sinon CPU.
    """
    try:
        params = {"tree_method": "hist", "device": "cuda"}
        dtrain = xgb.DMatrix(np.array([[0, 1], [1, 0]]), label=np.array([0, 1]))
        xgb.train(params=params, dtrain=dtrain, num_boost_round=1)
        print("üî• GPU disponible - entra√Ænement acc√©l√©r√© activ√©")
        return True
    except xgb.core.XGBoostError:
        print("üêå GPU non disponible - utilisation du CPU")
        return False


# --- Point d'entr√©e pour Docker ou CLI ---
if __name__ == "__main__":
    result = train()
    print(json.dumps(result, indent=2))
